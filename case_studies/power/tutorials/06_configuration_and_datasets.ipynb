{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 6: Configuration & Datasets\n",
    "\n",
    "**Goal:** Configure environments with YAML files and time-series datasets.\n",
    "\n",
    "**Time:** ~10 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Why Configuration Matters\n",
    "\n",
    "Production environments need:\n",
    "- **Reproducibility**: Same config → same environment\n",
    "- **Flexibility**: Change parameters without code changes\n",
    "- **Time-series data**: Load profiles, prices, renewable generation\n",
    "\n",
    "HERON uses:\n",
    "- **YAML files** for environment configuration\n",
    "- **Pickle files** for time-series datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Understanding the Setup Structure\n",
    "\n",
    "A HERON setup is a directory with configuration and data:\n",
    "\n",
    "```\n",
    "powergrid/setups/ieee34_ieee13/\n",
    "├── config.yml      # Environment configuration\n",
    "└── data.pkl        # Time-series data (load, solar, wind, prices)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Create a sample setup directory\n",
    "setup_dir = Path('sample_setup')\n",
    "setup_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Created setup directory: {setup_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Creating a Configuration File\n",
    "\n",
    "The `config.yml` defines:\n",
    "- Environment parameters (episode length, reward structure)\n",
    "- Microgrid configurations (devices, connections)\n",
    "- Dataset paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a sample configuration\n",
    "config = {\n",
    "    # Dataset reference\n",
    "    'dataset_path': 'data.pkl',\n",
    "    \n",
    "    # Environment parameters\n",
    "    'train': True,\n",
    "    'max_episode_steps': 96,  # 4 days at hourly resolution\n",
    "    'penalty': 10.0,          # Safety violation penalty\n",
    "    'share_reward': True,     # CTDE: shared rewards\n",
    "    \n",
    "    # DSO (Distribution System Operator) configuration\n",
    "    'dso_config': {\n",
    "        'name': 'DSO',\n",
    "        'network': 'ieee34',\n",
    "        'load_area': 'BANC',\n",
    "    },\n",
    "    \n",
    "    # Microgrid configurations (used to build agent hierarchy)\n",
    "    'microgrid_configs': [\n",
    "        {\n",
    "            'name': 'MG1',\n",
    "            'connection_bus': 'DSO Bus 850',\n",
    "            'base_power': 1.0,\n",
    "            'load_scale': 0.1,\n",
    "            'devices': [\n",
    "                {\n",
    "                    'type': 'Generator',\n",
    "                    'name': 'gen1',\n",
    "                    'config': {\n",
    "                        'bus': 'Bus 633',\n",
    "                        'p_max_MW': 2.0,\n",
    "                        'p_min_MW': 0.5,\n",
    "                        'cost_curve_coefs': [0.02, 10.0, 0.0],  # a*P^2 + b*P + c\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    'type': 'ESS',\n",
    "                    'name': 'ess1',\n",
    "                    'config': {\n",
    "                        'bus': 'Bus 634',\n",
    "                        'e_capacity_MWh': 5.0,\n",
    "                        'p_max_MW': 1.0,\n",
    "                        'p_min_MW': -1.0,  # Negative = charging\n",
    "                        'init_soc': 0.5,\n",
    "                        'soc_min': 0.1,\n",
    "                        'soc_max': 0.9,\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            'name': 'MG2',\n",
    "            'connection_bus': 'DSO Bus 860',\n",
    "            'devices': [\n",
    "                {\n",
    "                    'type': 'Generator',\n",
    "                    'name': 'gen2',\n",
    "                    'config': {\n",
    "                        'bus': 'Bus 633',\n",
    "                        'p_max_MW': 1.5,\n",
    "                        'p_min_MW': 0.3,\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            'name': 'MG3',\n",
    "            'connection_bus': 'DSO Bus 890',\n",
    "            'devices': [\n",
    "                {\n",
    "                    'type': 'ESS',\n",
    "                    'name': 'ess3',\n",
    "                    'config': {\n",
    "                        'bus': 'Bus 680',\n",
    "                        'e_capacity_MWh': 3.0,\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Save to YAML\n",
    "config_path = setup_dir / 'config.yml'\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(f\"Saved configuration to: {config_path}\")\n",
    "print(\"\\nConfiguration preview:\")\n",
    "print(yaml.dump(config, default_flow_style=False)[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Creating a Time-Series Dataset\n",
    "\n",
    "Datasets contain time-series profiles for:\n",
    "- **Load**: Demand profiles (typically daily/seasonal patterns)\n",
    "- **Solar**: PV generation (follows sun)\n",
    "- **Wind**: Wind generation (more variable)\n",
    "- **Price**: Electricity market prices\n",
    "\n",
    "The dataset is organized by area (e.g., 'BANC', 'NP15') for multi-region support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create realistic time-series data\n",
    "hours_per_year = 8760\n",
    "hours = np.arange(hours_per_year)\n",
    "\n",
    "# Daily and seasonal patterns\n",
    "hour_of_day = hours % 24\n",
    "day_of_year = hours // 24\n",
    "\n",
    "# Load profile: daily pattern + seasonal variation + noise\n",
    "daily_load = 0.6 + 0.3 * np.sin(2 * np.pi * (hour_of_day - 6) / 24)  # Peak at noon\n",
    "seasonal_load = 1.0 + 0.2 * np.sin(2 * np.pi * day_of_year / 365)    # Higher in summer\n",
    "load_profile = daily_load * seasonal_load + 0.05 * np.random.randn(hours_per_year)\n",
    "load_profile = np.clip(load_profile, 0.3, 1.5)\n",
    "\n",
    "# Solar profile: daylight hours only\n",
    "solar_profile = np.maximum(0, np.sin(np.pi * (hour_of_day - 6) / 12))  # 6am to 6pm\n",
    "solar_profile *= (hour_of_day >= 6) & (hour_of_day <= 18)\n",
    "solar_profile *= 0.8 + 0.2 * np.random.rand(hours_per_year)  # Cloud variability\n",
    "\n",
    "# Wind profile: more random, but with some correlation\n",
    "wind_profile = np.zeros(hours_per_year)\n",
    "wind_profile[0] = 0.5\n",
    "for i in range(1, hours_per_year):\n",
    "    wind_profile[i] = 0.9 * wind_profile[i-1] + 0.1 * np.random.rand()\n",
    "wind_profile = np.clip(wind_profile, 0.1, 0.9)\n",
    "\n",
    "# Price profile: correlates with load, higher during peak\n",
    "base_price = 30  # $/MWh\n",
    "price_profile = base_price + 20 * load_profile + 5 * np.random.randn(hours_per_year)\n",
    "price_profile = np.clip(price_profile, 15, 100)\n",
    "\n",
    "print(f\"Created {hours_per_year} hours of data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize one week of data\n",
    "week_hours = 168  # 7 days\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "axes[0, 0].plot(load_profile[:week_hours], 'b-')\n",
    "axes[0, 0].set_title('Load Profile')\n",
    "axes[0, 0].set_ylabel('Load (p.u.)')\n",
    "\n",
    "axes[0, 1].plot(solar_profile[:week_hours], 'orange')\n",
    "axes[0, 1].set_title('Solar Generation')\n",
    "axes[0, 1].set_ylabel('Solar (p.u.)')\n",
    "\n",
    "axes[1, 0].plot(wind_profile[:week_hours], 'g-')\n",
    "axes[1, 0].set_title('Wind Generation')\n",
    "axes[1, 0].set_ylabel('Wind (p.u.)')\n",
    "axes[1, 0].set_xlabel('Hour')\n",
    "\n",
    "axes[1, 1].plot(price_profile[:week_hours], 'r-')\n",
    "axes[1, 1].set_title('Electricity Price')\n",
    "axes[1, 1].set_ylabel('Price ($/MWh)')\n",
    "axes[1, 1].set_xlabel('Hour')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/test and save as pickle\n",
    "# Dataset is organized by area for multi-region support\n",
    "train_hours = int(0.8 * hours_per_year)  # 80% for training\n",
    "\n",
    "dataset = {\n",
    "    'train': {\n",
    "        # Load profiles by area\n",
    "        'load': {\n",
    "            'BANC': load_profile[:train_hours],\n",
    "            'AVA': load_profile[:train_hours] * 0.9,  # Slightly different\n",
    "        },\n",
    "        # Renewable profiles by region\n",
    "        'solar': {\n",
    "            'NP15': solar_profile[:train_hours],\n",
    "        },\n",
    "        'wind': {\n",
    "            'NP15': wind_profile[:train_hours],\n",
    "        },\n",
    "        # Price by node\n",
    "        'price': {\n",
    "            '0096WD_7_N001': price_profile[:train_hours],\n",
    "        },\n",
    "    },\n",
    "    'test': {\n",
    "        'load': {\n",
    "            'BANC': load_profile[train_hours:],\n",
    "            'AVA': load_profile[train_hours:] * 0.9,\n",
    "        },\n",
    "        'solar': {\n",
    "            'NP15': solar_profile[train_hours:],\n",
    "        },\n",
    "        'wind': {\n",
    "            'NP15': wind_profile[train_hours:],\n",
    "        },\n",
    "        'price': {\n",
    "            '0096WD_7_N001': price_profile[train_hours:],\n",
    "        },\n",
    "    },\n",
    "    'metadata': {\n",
    "        'resolution': 'hourly',\n",
    "        'units': {\n",
    "            'load': 'p.u.',\n",
    "            'solar': 'p.u. of rated',\n",
    "            'wind': 'p.u. of rated',\n",
    "            'price': '$/MWh',\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "# Save to pickle\n",
    "data_path = setup_dir / 'data.pkl'\n",
    "with open(data_path, 'wb') as f:\n",
    "    pickle.dump(dataset, f)\n",
    "\n",
    "print(f\"Saved dataset to: {data_path}\")\n",
    "print(f\"Train samples: {len(dataset['train']['load']['BANC'])}\")\n",
    "print(f\"Test samples: {len(dataset['test']['load']['BANC'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Loading Setups\n",
    "\n",
    "Create a loader to manage setups. This is similar to `powergrid.utils.loader.load_dataset()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_setup(setup_path: str) -> dict:\n",
    "    \"\"\"Load a HERON setup from directory.\n",
    "    \n",
    "    Args:\n",
    "        setup_path: Path to setup directory\n",
    "        \n",
    "    Returns:\n",
    "        Configuration dict with resolved dataset\n",
    "    \"\"\"\n",
    "    setup_dir = Path(setup_path)\n",
    "    \n",
    "    # Load YAML config\n",
    "    config_path = setup_dir / 'config.yml'\n",
    "    with open(config_path) as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    # Resolve and load dataset\n",
    "    if 'dataset_path' in config:\n",
    "        data_path = setup_dir / config['dataset_path']\n",
    "        with open(data_path, 'rb') as f:\n",
    "            config['dataset'] = pickle.load(f)\n",
    "        config['dataset_path'] = str(data_path)\n",
    "    \n",
    "    return config\n",
    "\n",
    "\n",
    "# Test loading\n",
    "loaded_config = load_setup('sample_setup')\n",
    "\n",
    "print(\"Loaded configuration:\")\n",
    "print(f\"  max_episode_steps: {loaded_config['max_episode_steps']}\")\n",
    "print(f\"  share_reward: {loaded_config['share_reward']}\")\n",
    "print(f\"  microgrids: {[mg['name'] for mg in loaded_config['microgrid_configs']]}\")\n",
    "print(f\"  dataset keys: {list(loaded_config['dataset'].keys())}\")\n",
    "print(f\"  train load areas: {list(loaded_config['dataset']['train']['load'].keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Building Agents from Configuration\n",
    "\n",
    "Use the configuration to build the agent hierarchy (bottom-up pattern from Tutorial 02)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "\n",
    "def build_agents_from_config(config: dict) -> Dict[str, Any]:\n",
    "    \"\"\"Build agent hierarchy from configuration.\n",
    "    \n",
    "    This demonstrates the bottom-up building pattern:\n",
    "    1. Create DeviceAgents (FieldAgent level)\n",
    "    2. Create PowerGridAgents (CoordinatorAgent level) with device subordinates\n",
    "    3. Create GridSystemAgent (SystemAgent level) with microgrid subordinates\n",
    "    \n",
    "    Args:\n",
    "        config: Loaded configuration dict\n",
    "        \n",
    "    Returns:\n",
    "        Dict with 'system_agent' and 'microgrids' keys\n",
    "    \"\"\"\n",
    "    # In a real implementation, you would import from powergrid:\n",
    "    # from powergrid.agents import Generator, ESS, Transformer, PowerGridAgent\n",
    "    # from powergrid.agents.grid_system_agent import GridSystemAgent\n",
    "    \n",
    "    microgrids = {}\n",
    "    \n",
    "    for mg_config in config.get('microgrid_configs', []):\n",
    "        mg_name = mg_config['name']\n",
    "        \n",
    "        # Step 1: Build device agents (FieldAgent level)\n",
    "        devices = {}\n",
    "        for dev_cfg in mg_config.get('devices', []):\n",
    "            device_type = dev_cfg['type']\n",
    "            device_name = dev_cfg['name']\n",
    "            device_config = dev_cfg.get('config', {})\n",
    "            \n",
    "            # In real code: device = DeviceClass(agent_id=device_name, **device_config)\n",
    "            devices[device_name] = {\n",
    "                'type': device_type,\n",
    "                'config': device_config,\n",
    "            }\n",
    "            print(f\"  Created {device_type}: {device_name}\")\n",
    "        \n",
    "        # Step 2: Build coordinator with device subordinates\n",
    "        # In real code: microgrid = PowerGridAgent(agent_id=mg_name, subordinates=devices)\n",
    "        microgrids[mg_name] = {\n",
    "            'name': mg_name,\n",
    "            'devices': devices,\n",
    "            'connection_bus': mg_config.get('connection_bus'),\n",
    "        }\n",
    "        print(f\"Created PowerGridAgent: {mg_name} with {len(devices)} devices\")\n",
    "    \n",
    "    # Step 3: Build system agent with microgrid subordinates\n",
    "    # In real code: system = GridSystemAgent(agent_id='system', subordinates=microgrids)\n",
    "    system_agent = {\n",
    "        'type': 'GridSystemAgent',\n",
    "        'subordinates': microgrids,\n",
    "    }\n",
    "    print(f\"Created GridSystemAgent with {len(microgrids)} microgrids\")\n",
    "    \n",
    "    return {\n",
    "        'system_agent': system_agent,\n",
    "        'microgrids': microgrids,\n",
    "    }\n",
    "\n",
    "\n",
    "# Build from loaded config\n",
    "print(\"Building agent hierarchy from config:\")\n",
    "print(\"=\" * 50)\n",
    "agents = build_agents_from_config(loaded_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Using Dataset in Environment Step\n",
    "\n",
    "Time-series data drives the simulation. The environment reads profiles and pushes them to agents via the ProxyAgent's global state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetManager:\n",
    "    \"\"\"Manages time-series dataset access during simulation.\n",
    "    \n",
    "    This is similar to how HierarchicalMicrogridEnv._update_profiles() works.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset: dict, load_area: str = 'BANC', renew_area: str = 'NP15'):\n",
    "        self.dataset = dataset\n",
    "        self.load_area = load_area\n",
    "        self.renew_area = renew_area\n",
    "        self.t = 0\n",
    "        \n",
    "        # Get max timesteps from price data\n",
    "        self.max_t = len(dataset.get('price', {}).get('0096WD_7_N001', []))\n",
    "    \n",
    "    def reset(self, start_timestep: int = 0):\n",
    "        \"\"\"Reset to specific timestep (for random day selection).\"\"\"\n",
    "        self.t = start_timestep\n",
    "    \n",
    "    def step(self) -> dict:\n",
    "        \"\"\"Get current timestep data and advance.\"\"\"\n",
    "        hour = self.t % self.max_t\n",
    "        \n",
    "        data = {\n",
    "            'load': float(self.dataset['load'][self.load_area][hour]),\n",
    "            'solar': float(self.dataset['solar'][self.renew_area][hour]),\n",
    "            'wind': float(self.dataset['wind'][self.renew_area][hour]),\n",
    "            'price': float(self.dataset['price']['0096WD_7_N001'][hour]),\n",
    "            'timestep': self.t,\n",
    "            'hour': hour,\n",
    "        }\n",
    "        self.t += 1\n",
    "        return data\n",
    "    \n",
    "    def peek(self, horizon: int = 24) -> dict:\n",
    "        \"\"\"Get forecast for next `horizon` hours.\"\"\"\n",
    "        end = min(self.t + horizon, self.max_t)\n",
    "        return {\n",
    "            'load': self.dataset['load'][self.load_area][self.t:end],\n",
    "            'solar': self.dataset['solar'][self.renew_area][self.t:end],\n",
    "            'wind': self.dataset['wind'][self.renew_area][self.t:end],\n",
    "            'price': self.dataset['price']['0096WD_7_N001'][self.t:end],\n",
    "        }\n",
    "\n",
    "\n",
    "# Demo usage with train data\n",
    "dm = DatasetManager(loaded_config['dataset']['train'])\n",
    "\n",
    "print(\"Simulating 5 timesteps:\")\n",
    "for step in range(5):\n",
    "    data = dm.step()\n",
    "    print(f\"  t={step}: load={data['load']:.3f}, solar={data['solar']:.3f}, \"\n",
    "          f\"wind={data['wind']:.3f}, price=${data['price']:.2f}/MWh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Setup Structure**\n",
    "   ```\n",
    "   setup_name/\n",
    "   ├── config.yml    # YAML configuration\n",
    "   └── data.pkl      # Pickle dataset\n",
    "   ```\n",
    "\n",
    "2. **Configuration File**\n",
    "   - Environment params: `max_episode_steps`, `penalty`, `share_reward`\n",
    "   - Microgrid configs: devices, connections, parameters\n",
    "   - Dataset reference: `dataset_path`\n",
    "\n",
    "3. **Dataset Format** (area-based for multi-region support)\n",
    "   ```python\n",
    "   {\n",
    "       'train': {\n",
    "           'load': {'BANC': [...], 'AVA': [...]},\n",
    "           'solar': {'NP15': [...]},\n",
    "           'wind': {'NP15': [...]},\n",
    "           'price': {'0096WD_7_N001': [...]},\n",
    "       },\n",
    "       'test': {...},\n",
    "       'metadata': {'resolution': 'hourly', 'units': {...}},\n",
    "   }\n",
    "   ```\n",
    "\n",
    "4. **Loading and Building Pattern**\n",
    "   ```python\n",
    "   config = load_setup('my_setup')\n",
    "   agents = build_agents_from_config(config)\n",
    "   env = HierarchicalMicrogridEnv(\n",
    "       system_agent=agents['system_agent'],\n",
    "       dataset_path=config['dataset_path'],\n",
    "   )\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** [07_custom_protocols.ipynb](07_custom_protocols.ipynb) — Create custom coordination protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "import shutil\n",
    "shutil.rmtree('sample_setup')\n",
    "print(\"Cleaned up sample_setup directory\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
