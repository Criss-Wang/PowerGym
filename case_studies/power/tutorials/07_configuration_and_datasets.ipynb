{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Tutorial 7: Configuration & Datasets\n",
    "\n",
    "**Goal:** Configure environments with YAML files and time-series datasets.\n",
    "\n",
    "**Time:** ~10 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Why Configuration Matters\n",
    "\n",
    "Production environments need:\n",
    "- **Reproducibility**: Same config → same environment\n",
    "- **Flexibility**: Change parameters without code changes\n",
    "- **Time-series data**: Load profiles, prices, renewable generation\n",
    "\n",
    "HERON uses:\n",
    "- **YAML files** for environment configuration\n",
    "- **Pickle files** for time-series datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Step 1: Understanding the Setup Structure\n",
    "\n",
    "A HERON setup is a directory with configuration and data:\n",
    "\n",
    "```\n",
    "powergrid/setups/ieee34_ieee13/\n",
    "├── config.yml      # Environment configuration\n",
    "└── data.pkl        # Time-series data (load, solar, wind, prices)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Create a sample setup directory\n",
    "setup_dir = Path('sample_setup')\n",
    "setup_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Created setup directory: {setup_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Step 2: Creating a Configuration File\n",
    "\n",
    "The `config.yml` defines:\n",
    "- Environment parameters (episode length, reward structure)\n",
    "- Microgrid configurations (devices, connections)\n",
    "- Dataset paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a sample configuration\n",
    "config = {\n",
    "    # Dataset reference\n",
    "    'dataset_path': 'data.pkl',\n",
    "    \n",
    "    # Environment parameters\n",
    "    'train': True,\n",
    "    'max_episode_steps': 96,  # 4 days at hourly resolution\n",
    "    'penalty': 10.0,          # Safety violation penalty\n",
    "    'share_reward': True,     # CTDE: shared rewards\n",
    "    \n",
    "    # DSO (Distribution System Operator) configuration\n",
    "    'dso_config': {\n",
    "        'name': 'DSO',\n",
    "        'network': 'ieee34',\n",
    "        'load_area': 'BANC',\n",
    "    },\n",
    "    \n",
    "    # Microgrid configurations\n",
    "    'microgrid_configs': [\n",
    "        {\n",
    "            'name': 'MG1',\n",
    "            'connection_bus': 'DSO Bus 850',\n",
    "            'base_power': 1.0,\n",
    "            'load_scale': 0.1,\n",
    "            'devices': [\n",
    "                {\n",
    "                    'type': 'Generator',\n",
    "                    'name': 'gen1',\n",
    "                    'device_state_config': {\n",
    "                        'bus': 'Bus 633',\n",
    "                        'p_max_MW': 2.0,\n",
    "                        'p_min_MW': 0.5,\n",
    "                        'cost_curve_coefs': [0.02, 10.0, 0.0],  # a*P^2 + b*P + c\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    'type': 'ESS',\n",
    "                    'name': 'ess1',\n",
    "                    'device_state_config': {\n",
    "                        'bus': 'Bus 634',\n",
    "                        'e_capacity_MWh': 5.0,\n",
    "                        'p_max_MW': 1.0,\n",
    "                        'p_min_MW': -1.0,  # Negative = charging\n",
    "                        'init_soc': 0.5,\n",
    "                        'soc_min': 0.1,\n",
    "                        'soc_max': 0.9,\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            'name': 'MG2',\n",
    "            'connection_bus': 'DSO Bus 860',\n",
    "            'devices': [\n",
    "                {\n",
    "                    'type': 'Generator',\n",
    "                    'name': 'gen2',\n",
    "                    'device_state_config': {\n",
    "                        'bus': 'Bus 633',\n",
    "                        'p_max_MW': 1.5,\n",
    "                        'p_min_MW': 0.3,\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            'name': 'MG3',\n",
    "            'connection_bus': 'DSO Bus 890',\n",
    "            'devices': [\n",
    "                {\n",
    "                    'type': 'ESS',\n",
    "                    'name': 'ess3',\n",
    "                    'device_state_config': {\n",
    "                        'bus': 'Bus 680',\n",
    "                        'e_capacity_MWh': 3.0,\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Save to YAML\n",
    "config_path = setup_dir / 'config.yml'\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(f\"Saved configuration to: {config_path}\")\n",
    "print(\"\\nConfiguration preview:\")\n",
    "print(yaml.dump(config, default_flow_style=False)[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Step 3: Creating a Time-Series Dataset\n",
    "\n",
    "Datasets contain time-series profiles for:\n",
    "- **Load**: Demand profiles (typically daily/seasonal patterns)\n",
    "- **Solar**: PV generation (follows sun)\n",
    "- **Wind**: Wind generation (more variable)\n",
    "- **Price**: Electricity market prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create realistic time-series data\n",
    "hours_per_year = 8760\n",
    "hours = np.arange(hours_per_year)\n",
    "\n",
    "# Daily and seasonal patterns\n",
    "hour_of_day = hours % 24\n",
    "day_of_year = hours // 24\n",
    "\n",
    "# Load profile: daily pattern + seasonal variation + noise\n",
    "daily_load = 0.6 + 0.3 * np.sin(2 * np.pi * (hour_of_day - 6) / 24)  # Peak at noon\n",
    "seasonal_load = 1.0 + 0.2 * np.sin(2 * np.pi * day_of_year / 365)    # Higher in summer\n",
    "load_profile = daily_load * seasonal_load + 0.05 * np.random.randn(hours_per_year)\n",
    "load_profile = np.clip(load_profile, 0.3, 1.5)\n",
    "\n",
    "# Solar profile: daylight hours only\n",
    "solar_profile = np.maximum(0, np.sin(np.pi * (hour_of_day - 6) / 12))  # 6am to 6pm\n",
    "solar_profile *= (hour_of_day >= 6) & (hour_of_day <= 18)\n",
    "solar_profile *= 0.8 + 0.2 * np.random.rand(hours_per_year)  # Cloud variability\n",
    "\n",
    "# Wind profile: more random, but with some correlation\n",
    "wind_profile = np.zeros(hours_per_year)\n",
    "wind_profile[0] = 0.5\n",
    "for i in range(1, hours_per_year):\n",
    "    wind_profile[i] = 0.9 * wind_profile[i-1] + 0.1 * np.random.rand()\n",
    "wind_profile = np.clip(wind_profile, 0.1, 0.9)\n",
    "\n",
    "# Price profile: correlates with load, higher during peak\n",
    "base_price = 30  # $/MWh\n",
    "price_profile = base_price + 20 * load_profile + 5 * np.random.randn(hours_per_year)\n",
    "price_profile = np.clip(price_profile, 15, 100)\n",
    "\n",
    "print(f\"Created {hours_per_year} hours of data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize one week of data\n",
    "week_hours = 168  # 7 days\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "axes[0, 0].plot(load_profile[:week_hours], 'b-')\n",
    "axes[0, 0].set_title('Load Profile')\n",
    "axes[0, 0].set_ylabel('Load (p.u.)')\n",
    "\n",
    "axes[0, 1].plot(solar_profile[:week_hours], 'orange')\n",
    "axes[0, 1].set_title('Solar Generation')\n",
    "axes[0, 1].set_ylabel('Solar (p.u.)')\n",
    "\n",
    "axes[1, 0].plot(wind_profile[:week_hours], 'g-')\n",
    "axes[1, 0].set_title('Wind Generation')\n",
    "axes[1, 0].set_ylabel('Wind (p.u.)')\n",
    "axes[1, 0].set_xlabel('Hour')\n",
    "\n",
    "axes[1, 1].plot(price_profile[:week_hours], 'r-')\n",
    "axes[1, 1].set_title('Electricity Price')\n",
    "axes[1, 1].set_ylabel('Price ($/MWh)')\n",
    "axes[1, 1].set_xlabel('Hour')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/test and save as pickle\n",
    "train_hours = int(0.8 * hours_per_year)  # 80% for training\n",
    "\n",
    "dataset = {\n",
    "    'train': {\n",
    "        'load': load_profile[:train_hours],\n",
    "        'solar': solar_profile[:train_hours],\n",
    "        'wind': wind_profile[:train_hours],\n",
    "        'price': price_profile[:train_hours],\n",
    "    },\n",
    "    'test': {\n",
    "        'load': load_profile[train_hours:],\n",
    "        'solar': solar_profile[train_hours:],\n",
    "        'wind': wind_profile[train_hours:],\n",
    "        'price': price_profile[train_hours:],\n",
    "    },\n",
    "    'metadata': {\n",
    "        'resolution': 'hourly',\n",
    "        'units': {\n",
    "            'load': 'p.u.',\n",
    "            'solar': 'p.u. of rated',\n",
    "            'wind': 'p.u. of rated',\n",
    "            'price': '$/MWh',\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "# Save to pickle\n",
    "data_path = setup_dir / 'data.pkl'\n",
    "with open(data_path, 'wb') as f:\n",
    "    pickle.dump(dataset, f)\n",
    "\n",
    "print(f\"Saved dataset to: {data_path}\")\n",
    "print(f\"Train samples: {len(dataset['train']['load'])}\")\n",
    "print(f\"Test samples: {len(dataset['test']['load'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Step 4: Loading Setups\n",
    "\n",
    "Create a loader to manage setups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_setup(setup_path: str) -> dict:\n",
    "    \"\"\"Load a HERON setup from directory.\n",
    "    \n",
    "    Args:\n",
    "        setup_path: Path to setup directory\n",
    "        \n",
    "    Returns:\n",
    "        Configuration dict with resolved dataset\n",
    "    \"\"\"\n",
    "    setup_dir = Path(setup_path)\n",
    "    \n",
    "    # Load YAML config\n",
    "    config_path = setup_dir / 'config.yml'\n",
    "    with open(config_path) as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    # Resolve and load dataset\n",
    "    if 'dataset_path' in config:\n",
    "        data_path = setup_dir / config['dataset_path']\n",
    "        with open(data_path, 'rb') as f:\n",
    "            config['dataset'] = pickle.load(f)\n",
    "        config['dataset_path'] = str(data_path)\n",
    "    \n",
    "    return config\n",
    "\n",
    "\n",
    "# Test loading\n",
    "loaded_config = load_setup('sample_setup')\n",
    "\n",
    "print(\"Loaded configuration:\")\n",
    "print(f\"  max_episode_steps: {loaded_config['max_episode_steps']}\")\n",
    "print(f\"  share_reward: {loaded_config['share_reward']}\")\n",
    "print(f\"  microgrids: {[mg['name'] for mg in loaded_config['microgrid_configs']]}\")\n",
    "print(f\"  dataset keys: {list(loaded_config['dataset'].keys())}\")\n",
    "print(f\"  train samples: {len(loaded_config['dataset']['train']['load'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Step 5: Using Configuration in Environment\n",
    "\n",
    "Here's how to use the loaded configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using config in environment creation\n",
    "def create_env_from_config(config: dict):\n",
    "    \"\"\"Create environment from loaded configuration.\"\"\"\n",
    "    \n",
    "    # Extract parameters\n",
    "    max_steps = config.get('max_episode_steps', 96)\n",
    "    share_reward = config.get('share_reward', True)\n",
    "    penalty = config.get('penalty', 10.0)\n",
    "    \n",
    "    # Get dataset for current mode (train/test)\n",
    "    mode = 'train' if config.get('train', True) else 'test'\n",
    "    dataset = config.get('dataset', {}).get(mode, {})\n",
    "    \n",
    "    # Parse microgrid configs\n",
    "    microgrids = []\n",
    "    for mg_config in config.get('microgrid_configs', []):\n",
    "        mg = {\n",
    "            'name': mg_config['name'],\n",
    "            'devices': mg_config.get('devices', []),\n",
    "            'connection_bus': mg_config.get('connection_bus'),\n",
    "        }\n",
    "        microgrids.append(mg)\n",
    "    \n",
    "    print(f\"Environment config:\")\n",
    "    print(f\"  max_steps: {max_steps}\")\n",
    "    print(f\"  share_reward: {share_reward}\")\n",
    "    print(f\"  mode: {mode}\")\n",
    "    print(f\"  microgrids: {len(microgrids)}\")\n",
    "    for mg in microgrids:\n",
    "        print(f\"    - {mg['name']}: {len(mg['devices'])} devices\")\n",
    "    \n",
    "    return {\n",
    "        'max_steps': max_steps,\n",
    "        'share_reward': share_reward,\n",
    "        'penalty': penalty,\n",
    "        'microgrids': microgrids,\n",
    "        'dataset': dataset,\n",
    "    }\n",
    "\n",
    "\n",
    "env_config = create_env_from_config(loaded_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Step 6: Using Dataset in Environment Step\n",
    "\n",
    "Time-series data drives the simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetManager:\n",
    "    \"\"\"Manages time-series dataset access during simulation.\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset: dict):\n",
    "        self.dataset = dataset\n",
    "        self.t = 0\n",
    "        self.max_t = len(dataset.get('load', []))\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset to start of dataset.\"\"\"\n",
    "        self.t = 0\n",
    "    \n",
    "    def step(self) -> dict:\n",
    "        \"\"\"Get current timestep data and advance.\"\"\"\n",
    "        data = {\n",
    "            'load': self.dataset['load'][self.t % self.max_t],\n",
    "            'solar': self.dataset['solar'][self.t % self.max_t],\n",
    "            'wind': self.dataset['wind'][self.t % self.max_t],\n",
    "            'price': self.dataset['price'][self.t % self.max_t],\n",
    "        }\n",
    "        self.t += 1\n",
    "        return data\n",
    "    \n",
    "    def peek(self, horizon: int = 24) -> dict:\n",
    "        \"\"\"Get forecast for next `horizon` hours.\"\"\"\n",
    "        end = min(self.t + horizon, self.max_t)\n",
    "        return {\n",
    "            'load': self.dataset['load'][self.t:end],\n",
    "            'solar': self.dataset['solar'][self.t:end],\n",
    "            'wind': self.dataset['wind'][self.t:end],\n",
    "            'price': self.dataset['price'][self.t:end],\n",
    "        }\n",
    "\n",
    "\n",
    "# Demo usage\n",
    "dm = DatasetManager(env_config['dataset'])\n",
    "\n",
    "print(\"Simulating 5 timesteps:\")\n",
    "for step in range(5):\n",
    "    data = dm.step()\n",
    "    print(f\"  t={step}: load={data['load']:.3f}, solar={data['solar']:.3f}, \"\n",
    "          f\"wind={data['wind']:.3f}, price=${data['price']:.2f}/MWh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Setup Structure**\n",
    "   ```\n",
    "   setup_name/\n",
    "   ├── config.yml    # YAML configuration\n",
    "   └── data.pkl      # Pickle dataset\n",
    "   ```\n",
    "\n",
    "2. **Configuration File**\n",
    "   - Environment params: `max_episode_steps`, `penalty`, `share_reward`\n",
    "   - Microgrid configs: devices, connections, parameters\n",
    "   - Dataset reference: `dataset_path`\n",
    "\n",
    "3. **Dataset Format**\n",
    "   ```python\n",
    "   {\n",
    "       'train': {'load': [...], 'solar': [...], 'wind': [...], 'price': [...]},\n",
    "       'test': {'load': [...], ...},\n",
    "       'metadata': {'resolution': 'hourly', 'units': {...}},\n",
    "   }\n",
    "   ```\n",
    "\n",
    "4. **Loading Pattern**\n",
    "   ```python\n",
    "   config = load_setup('my_setup')\n",
    "   env = MyEnvironment(config)\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** [08_custom_protocols.ipynb](08_custom_protocols.ipynb) — Create custom coordination protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "import shutil\n",
    "shutil.rmtree('sample_setup')\n",
    "print(\"Cleaned up sample_setup directory\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
