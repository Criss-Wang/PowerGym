{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Building the Environment\n",
    "\n",
    "**Goal:** Create a PettingZoo-compatible environment using HERON's adapter.\n",
    "\n",
    "**Time:** ~15 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## The Environment's Role\n",
    "\n",
    "The environment **only talks to L3 SystemAgent**, which coordinates the hierarchy:\n",
    "\n",
    "```\n",
    "RLlib / StableBaselines3\n",
    "    │\n",
    "    └── PettingZoo API (step, reset, observe)\n",
    "            │\n",
    "            └── HERON Environment ←→ SystemAgent (L3)\n",
    "                                          │\n",
    "                                          ├── Microgrid 0 (L2 CoordinatorAgent)\n",
    "                                          │   ├── Battery (L1 FieldAgent)\n",
    "                                          │   └── Generator (L1 FieldAgent)\n",
    "                                          ├── Microgrid 1 ...\n",
    "                                          └── Microgrid 2 ...\n",
    "```\n",
    "\n",
    "**Critical pattern:** Environment ONLY interacts with L3. L3 coordinates L2. L2 coordinates L1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define Our Simple Agents\n",
    "\n",
    "Agents from Tutorial 2 - **no `step()` method** (physics lives in environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "from gymnasium.spaces import Box\n",
    "\n",
    "from heron.core.feature import FeatureProvider\n",
    "from heron.agents.field_agent import FieldAgent\n",
    "from heron.agents.coordinator_agent import CoordinatorAgent\n",
    "from heron.agents.system_agent import SystemAgent\n",
    "from heron.protocols.vertical import SetpointProtocol\n",
    "from heron.scheduling.tick_config import TickConfig\n",
    "\n",
    "\n",
    "# === Features ===\n",
    "@dataclass\n",
    "class BatterySOC(FeatureProvider):\n",
    "    visibility = ['owner', 'upper_level']\n",
    "    soc: float = 0.5\n",
    "\n",
    "    def vector(self) -> np.ndarray:\n",
    "        return np.array([self.soc], dtype=np.float32)\n",
    "\n",
    "    def names(self): return ['soc']\n",
    "    def to_dict(self): return {'soc': self.soc}\n",
    "    @classmethod\n",
    "    def from_dict(cls, d): return cls(**d)\n",
    "    def set_values(self, **kw):\n",
    "        if 'soc' in kw: self.soc = np.clip(float(kw['soc']), 0.1, 0.9)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GenOutput(FeatureProvider):\n",
    "    visibility = ['owner', 'upper_level', 'system']\n",
    "    p_mw: float = 0.0\n",
    "    p_max: float = 5.0\n",
    "\n",
    "    def vector(self) -> np.ndarray:\n",
    "        return np.array([self.p_mw / self.p_max], dtype=np.float32)\n",
    "\n",
    "    def names(self): return ['p_norm']\n",
    "    def to_dict(self): return {'p_mw': self.p_mw, 'p_max': self.p_max}\n",
    "    @classmethod\n",
    "    def from_dict(cls, d): return cls(**d)\n",
    "    def set_values(self, **kw):\n",
    "        if 'p_mw' in kw: self.p_mw = float(kw['p_mw'])\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SystemFrequency(FeatureProvider):\n",
    "    visibility = ['system']\n",
    "    frequency_hz: float = 60.0\n",
    "\n",
    "    def vector(self) -> np.ndarray:\n",
    "        return np.array([self.frequency_hz - 60.0], dtype=np.float32)\n",
    "\n",
    "    def names(self): return ['freq_deviation']\n",
    "    def to_dict(self): return {'frequency_hz': self.frequency_hz}\n",
    "    @classmethod\n",
    "    def from_dict(cls, d): return cls(**d)\n",
    "    def set_values(self, **kw):\n",
    "        if 'frequency_hz' in kw: self.frequency_hz = float(kw['frequency_hz'])\n",
    "\n",
    "\n",
    "# === L1: Field Agents ===\n",
    "class SimpleBattery(FieldAgent):\n",
    "    def __init__(self, agent_id: str, capacity: float = 2.0, **kwargs):\n",
    "        self.capacity = capacity\n",
    "        self.max_power = 0.5\n",
    "        super().__init__(agent_id=agent_id, **kwargs)\n",
    "\n",
    "    def set_state(self):\n",
    "        self.soc_feature = BatterySOC(soc=0.5)\n",
    "        self.state.features.append(self.soc_feature)\n",
    "\n",
    "    def set_action(self):\n",
    "        self.action.set_specs(dim_c=1, range=(np.array([-1.0]), np.array([1.0])))\n",
    "\n",
    "    def update_state(self, **env_state):\n",
    "        if 'soc' in env_state:\n",
    "            self.soc_feature.set_values(soc=env_state['soc'])\n",
    "\n",
    "\n",
    "class SimpleGen(FieldAgent):\n",
    "    def __init__(self, agent_id: str, p_max: float = 5.0, cost_per_mwh: float = 50.0, **kwargs):\n",
    "        self.p_max = p_max\n",
    "        self.cost_per_mwh = cost_per_mwh\n",
    "        super().__init__(agent_id=agent_id, **kwargs)\n",
    "\n",
    "    def set_state(self):\n",
    "        self.output_feature = GenOutput(p_mw=0.0, p_max=self.p_max)\n",
    "        self.state.features.append(self.output_feature)\n",
    "\n",
    "    def set_action(self):\n",
    "        self.action.set_specs(dim_c=1, range=(np.array([0.0]), np.array([1.0])))\n",
    "\n",
    "    def update_state(self, **env_state):\n",
    "        if 'p_mw' in env_state:\n",
    "            self.output_feature.set_values(p_mw=env_state['p_mw'])\n",
    "\n",
    "\n",
    "# === L2: Coordinator Agent ===\n",
    "class SimpleMicrogrid(CoordinatorAgent):\n",
    "    def __init__(self, agent_id: str, load: float = 3.0, **kwargs):\n",
    "        self.load = load\n",
    "        self._my_id = agent_id\n",
    "        super().__init__(\n",
    "            agent_id=agent_id,\n",
    "            protocol=SetpointProtocol(),\n",
    "            tick_config=TickConfig.deterministic(tick_interval=60.0),\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def _build_subordinates(self, configs, env_id=None, upstream_id=None):\n",
    "        self.battery = SimpleBattery(f'{self._my_id}_bat', upstream_id=self._my_id)\n",
    "        self.gen = SimpleGen(f'{self._my_id}_gen', upstream_id=self._my_id)\n",
    "        return {self.battery.agent_id: self.battery, self.gen.agent_id: self.gen}\n",
    "\n",
    "\n",
    "# === L3: System Agent ===\n",
    "class SimpleGridSystem(SystemAgent):\n",
    "    \"\"\"System agent managing multiple microgrids.\"\"\"\n",
    "    \n",
    "    def __init__(self, agent_id: str, microgrids: List[SimpleMicrogrid] = None):\n",
    "        self._init_mgs = microgrids or []\n",
    "        super().__init__(\n",
    "            agent_id=agent_id,\n",
    "            tick_config=TickConfig.deterministic(tick_interval=300.0),\n",
    "        )\n",
    "        # Setup coordinators\n",
    "        if microgrids:\n",
    "            self.coordinators = {mg.agent_id: mg for mg in microgrids}\n",
    "            for mg in microgrids:\n",
    "                mg.upstream_id = agent_id\n",
    "\n",
    "    def set_state(self):\n",
    "        self.freq_feature = SystemFrequency(frequency_hz=60.0)\n",
    "        self.state.features.append(self.freq_feature)\n",
    "\n",
    "\n",
    "print(\"All 3 levels defined: FieldAgent -> CoordinatorAgent -> SystemAgent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Build the Multi-Agent Environment\n",
    "\n",
    "HERON provides `PettingZooParallelEnv` - an adapter that combines:\n",
    "- PettingZoo's `ParallelEnv` interface (for RL framework compatibility)\n",
    "- HERON's `HeronEnvCore` mixin (for agent management, event-driven execution)\n",
    "\n",
    "**Critical Design Principle: Environment ↔ L3 Only**\n",
    "\n",
    "The environment should:\n",
    "1. **Maintain its own physics state** (battery SOCs, gen outputs, etc.)\n",
    "2. **Only interact with SystemAgent (L3)** - never directly access L2 or L1\n",
    "3. **Push state via `update_from_environment()`** - L3 propagates to L2 → L1\n",
    "4. **Get observations via `observe()`** - flows L1 → L2 → L3 → Env\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from heron.envs.adapters import PettingZooParallelEnv\nfrom heron.core.observation import OBS_KEY_SUBORDINATE_OBS\n\n\nclass SimpleMultiMicrogridEnv(PettingZooParallelEnv):\n    \"\"\"Multi-agent environment demonstrating proper HERON patterns.\n    \n    Key Patterns:\n    1. Environment ONLY talks to SystemAgent (L3)\n    2. Observations flow: L1 → L2 → L3 → Env\n    3. Actions flow: Env → L3 → L2 → L1\n    4. State updates flow: Env → L3 → L2 → L1\n    \"\"\"\n    \n    metadata = {'render_modes': ['human'], 'name': 'simple_microgrids_v0'}\n    \n    def __init__(\n        self,\n        num_microgrids: int = 3,\n        max_steps: int = 96,\n        share_reward: bool = True,\n        penalty: float = 10.0,\n    ):\n        super().__init__(env_id=\"simple_microgrids\")\n        \n        self.num_microgrids = num_microgrids\n        self.max_steps = max_steps\n        self.share_reward = share_reward\n        self.penalty = penalty\n        self.dt = 1.0\n        \n        # === ENVIRONMENT'S OWN PHYSICS STATE ===\n        self._physics = {\n            'frequency': 60.0,\n            'microgrids': {}\n        }\n        \n        loads = [3.0, 4.0, 2.5]\n        for i in range(num_microgrids):\n            mg_id = f'mg_{i}'\n            self._physics['microgrids'][mg_id] = {\n                'load': loads[i % len(loads)],\n                'battery': {'soc': 0.5, 'capacity': 2.0, 'max_power': 0.5},\n                'generator': {'p_mw': 0.0, 'p_max': 5.0, 'cost_per_mwh': 50.0}\n            }\n        \n        # === BUILD AGENT HIERARCHY (L3 -> L2 -> L1) ===\n        microgrid_list = []\n        for i in range(num_microgrids):\n            mg = SimpleMicrogrid(agent_id=f'mg_{i}', load=loads[i % len(loads)])\n            microgrid_list.append(mg)\n        \n        self._grid_system = SimpleGridSystem(\n            agent_id='grid_system',\n            microgrids=microgrid_list\n        )\n        self.set_system_agent(self._grid_system)\n        \n        # PettingZoo setup\n        self._mg_ids = [f'mg_{i}' for i in range(num_microgrids)]\n        self._set_agent_ids(self._mg_ids)\n        \n        obs_spaces = {aid: Box(-np.inf, np.inf, (3,), np.float32) for aid in self._mg_ids}\n        act_spaces = {aid: Box(np.array([-1, 0]), np.array([1, 1]), dtype=np.float32) \n                      for aid in self._mg_ids}\n        self._init_spaces(action_spaces=act_spaces, observation_spaces=obs_spaces)\n        self._step_count = 0\n    \n    def _build_env_state(self) -> Dict[str, Any]:\n        \"\"\"Build env_state dict for pushing to L3.\"\"\"\n        env_state = {\n            'system': {'SystemFrequency': {'frequency_hz': self._physics['frequency']}},\n            'coordinators': {}\n        }\n        for mg_id, mg_physics in self._physics['microgrids'].items():\n            bat_id, gen_id = f'{mg_id}_bat', f'{mg_id}_gen'\n            env_state['coordinators'][mg_id] = {\n                'subordinates': {\n                    bat_id: {'BatterySOC': {'soc': mg_physics['battery']['soc']}},\n                    gen_id: {'GenOutput': {'p_mw': mg_physics['generator']['p_mw']}}\n                }\n            }\n        return env_state\n    \n    def _extract_observations(self, sys_obs) -> Dict[str, np.ndarray]:\n        \"\"\"Extract per-microgrid observations from SystemAgent's observation.\"\"\"\n        observations = {}\n        for mg_id in self._mg_ids:\n            mg_physics = self._physics['microgrids'][mg_id]\n            observations[mg_id] = np.array([\n                mg_physics['battery']['soc'],\n                mg_physics['generator']['p_mw'] / mg_physics['generator']['p_max'],\n                mg_physics['load'] / 10.0\n            ], dtype=np.float32)\n        return observations\n    \n    def _get_global_state(self) -> Dict[str, Any]:\n        \"\"\"Build global_state dict for observe().\n        \n        global_state is optional context passed down to all agents during observe().\n        Use it for environment-wide info agents might need for observations:\n        - Simulation time, market prices, weather conditions, etc.\n        \n        In this simple tutorial, we don't need any global context,\n        so we return an empty dict. In real scenarios:\n        \n            return {\n                'time': self._step_count,\n                'market_price': self._electricity_price,\n                'weather': {'solar': 800, 'wind': 5.0},\n            }\n        \"\"\"\n        return {}\n    \n    def reset(self, seed=None, options=None):\n        self._step_count = 0\n        self._agents = self._possible_agents.copy()\n        \n        # Reset physics\n        self._physics['frequency'] = 60.0\n        for mg_id in self._physics['microgrids']:\n            self._physics['microgrids'][mg_id]['battery']['soc'] = 0.5\n            self._physics['microgrids'][mg_id]['generator']['p_mw'] = 0.0\n        \n        # Push to L3 → L2 → L1\n        self._grid_system.update_from_environment(self._build_env_state())\n        \n        # Get observations L1 → L2 → L3 → Env\n        sys_obs = self._grid_system.observe(global_state=self._get_global_state())\n        return self._extract_observations(sys_obs), {aid: {} for aid in self.agents}\n    \n    def step(self, actions: Dict[str, np.ndarray]):\n        \"\"\"Environment step with proper HERON action/state flow.\n        \n        Flow:\n        1. Get observation through L3 (for action routing context)\n        2. Route actions: L3.act() → L2.act() → L1.act()\n        3. Run physics (environment's job)\n        4. Push state: Env → L3 → L2 → L1\n        5. Get observations: L1 → L2 → L3 → Env\n        \"\"\"\n        self._step_count += 1\n        \n        # === 1. GET OBSERVATION THROUGH L3 ===\n        # global_state: optional context for agents (time, prices, weather, etc.)\n        # Empty dict here since our simple agents don't need global context\n        sys_obs = self._grid_system.observe(global_state=self._get_global_state())\n        \n        # === 2. ROUTE ACTIONS THROUGH HIERARCHY ===\n        # Actions flow: Env → L3 → L2 → L1\n        self._grid_system.act(sys_obs, upstream_action=actions)\n        \n        # === 3. RUN PHYSICS (environment's job) ===\n        total_gen, total_load, total_cost, total_imbalance = 0.0, 0.0, 0.0, 0.0\n        results = {}\n        \n        for mg_id in self._mg_ids:\n            action = actions.get(mg_id, np.zeros(2))\n            mg_phys = self._physics['microgrids'][mg_id]\n            bat, gen = mg_phys['battery'], mg_phys['generator']\n            \n            # Battery physics\n            bat_power = action[0] * bat['max_power']\n            bat['soc'] = np.clip(bat['soc'] + bat_power * self.dt / bat['capacity'], 0.1, 0.9)\n            \n            # Generator physics\n            gen_power = action[1] * gen['p_max']\n            gen['p_mw'] = gen_power\n            gen_cost = gen_power * self.dt * gen['cost_per_mwh']\n            \n            # Balance\n            imbalance = abs(mg_phys['load'] - (gen_power - bat_power))\n            results[mg_id] = {'cost': gen_cost, 'imbalance': imbalance}\n            total_gen += gen_power\n            total_load += mg_phys['load']\n            total_cost += gen_cost\n            total_imbalance += imbalance\n        \n        # System frequency\n        self._physics['frequency'] = 60.0 + (total_gen - total_load) * 0.01\n        \n        # === 4. PUSH STATE TO L3 (propagates to L2 → L1) ===\n        self._grid_system.update_from_environment(self._build_env_state())\n        \n        # === 5. GET OBSERVATIONS THROUGH L3 ===\n        sys_obs = self._grid_system.observe(global_state=self._get_global_state())\n        observations = self._extract_observations(sys_obs)\n        \n        # Rewards\n        collective_reward = -(total_cost + self.penalty * total_imbalance)\n        if self.share_reward:\n            rewards = {aid: collective_reward / self.num_microgrids for aid in self.agents}\n        else:\n            rewards = {aid: -(results[aid]['cost'] + self.penalty * results[aid]['imbalance'])\n                      for aid in self.agents}\n        \n        done = self._step_count >= self.max_steps\n        terminateds = {aid: done for aid in self.agents}\n        terminateds['__all__'] = done\n        truncateds = {aid: False for aid in self.agents}\n        truncateds['__all__'] = False\n        \n        return observations, rewards, terminateds, truncateds, {aid: results[aid] for aid in self.agents}\n\n\nprint(\"Environment with proper HERON action flow: Env → L3 → L2 → L1\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the environment with L3-only interaction\n",
    "env = SimpleMultiMicrogridEnv(num_microgrids=3, max_steps=10, share_reward=True)\n",
    "\n",
    "print(\"=== HERON 3-Level Hierarchy ===\")\n",
    "print(f\"L3 SystemAgent: {env.system_agent.agent_id}\")\n",
    "print(f\"L2 Coordinators: {list(env.system_agent.coordinators.keys())}\")\n",
    "for mg_id, mg in env.system_agent.coordinators.items():\n",
    "    print(f\"  {mg_id} -> L1 Subordinates: {list(mg.subordinates.keys())}\")\n",
    "\n",
    "print(f\"\\nRL Agents (PettingZoo): {env.possible_agents}\")\n",
    "print(f\"\\n=== Environment's Physics State (separate from agents) ===\")\n",
    "print(f\"env._physics keys: {list(env._physics.keys())}\")\n",
    "print(f\"mg_0 physics: battery_soc={env._physics['microgrids']['mg_0']['battery']['soc']}, \"\n",
    "      f\"gen_power={env._physics['microgrids']['mg_0']['generator']['p_mw']}\")\n",
    "\n",
    "# Reset - note: we access physics through env, observations through L3\n",
    "obs, infos = env.reset()\n",
    "print(f\"\\nAfter reset (observations came through L3):\")\n",
    "for aid, o in obs.items():\n",
    "    print(f\"  {aid}: {o}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Run steps - step() now handles action routing internally\nprint(\"Running 5 steps...\\n\")\nprint(\"Inside step():\")\nprint(\"  1. sys_obs = system_agent.observe()      # L1→L2→L3→Env\")\nprint(\"  2. system_agent.act(obs, actions)        # Env→L3→L2→L1\")\nprint(\"  3. Run physics                           # Environment's job\")\nprint(\"  4. system_agent.update_from_environment  # Env→L3→L2→L1\")\nprint(\"  5. Return observations                   # L1→L2→L3→Env\\n\")\n\nfor step in range(5):\n    # RL policy computes actions (random for testing)\n    actions = {aid: env.action_spaces[aid].sample() for aid in env.agents}\n    \n    # step() handles: observe → act → physics → update → return obs\n    obs, rewards, terminateds, truncateds, infos = env.step(actions)\n    \n    print(f\"Step {step + 1}:\")\n    for mg_id in env._mg_ids:\n        mg_phys = env._physics['microgrids'][mg_id]\n        print(f\"  {mg_id}: SOC={mg_phys['battery']['soc']:.2f}, \"\n              f\"Gen={mg_phys['generator']['p_mw']:.2f}MW\")\n    print(f\"  System Frequency: {env._physics['frequency']:.3f} Hz\")\n    print()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Understanding the L3-Only Pattern\n",
    "\n",
    "### Why Environment ↔ L3 Only?\n",
    "\n",
    "This pattern ensures clean separation of concerns:\n",
    "\n",
    "| Component | Responsibility |\n",
    "|-----------|---------------|\n",
    "| **Environment** | Physics simulation, reward calculation |\n",
    "| **SystemAgent (L3)** | Hierarchy coordination, state distribution |\n",
    "| **CoordinatorAgent (L2)** | Subordinate management, protocol execution |\n",
    "| **FieldAgent (L1)** | State representation, action execution |\n",
    "\n",
    "### Data Flow\n",
    "\n",
    "```\n",
    "┌─────────────────┐\n",
    "│   Environment   │ ← Maintains physics state\n",
    "└────────┬────────┘\n",
    "         │ update_from_environment(env_state)\n",
    "         ▼\n",
    "┌─────────────────┐\n",
    "│ SystemAgent (L3)│ ← Propagates to coordinators\n",
    "└────────┬────────┘\n",
    "         │ update_from_environment()\n",
    "         ▼\n",
    "┌─────────────────┐\n",
    "│Coordinator (L2) │ ← Propagates to subordinates\n",
    "└────────┬────────┘\n",
    "         │ update_from_environment()\n",
    "         ▼\n",
    "┌─────────────────┐\n",
    "│ FieldAgent (L1) │ ← Updates state features\n",
    "└─────────────────┘\n",
    "```\n",
    "\n",
    "### Why Shared Rewards?\n",
    "\n",
    "In **cooperative** settings, agents should optimize collective goals:\n",
    "```python\n",
    "if self.share_reward:\n",
    "    # All agents get same reward -> learn to cooperate\n",
    "    rewards = {aid: collective_reward / num_agents for aid in agents}\n",
    "```\n",
    "\n",
    "This is **Centralized Training with Decentralized Execution (CTDE)**.\n",
    "\n",
    "### Why Penalty for Imbalance?\n",
    "\n",
    "Power grids must balance supply and demand. The penalty:\n",
    "```python\n",
    "reward = -(cost + penalty * imbalance)\n",
    "```\n",
    "Encourages agents to coordinate generation with load."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Adding Configuration Support\n",
    "\n",
    "For production, environments should be configurable via dicts/YAML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example config (like what load_setup() would return)\n",
    "env_config = {\n",
    "    'num_microgrids': 3,\n",
    "    'max_steps': 96,\n",
    "    'share_reward': True,\n",
    "    'penalty': 10.0,\n",
    "    'train': True,\n",
    "    'centralized': True,\n",
    "}\n",
    "\n",
    "# Factory function for RLlib\n",
    "def create_env(config: Dict) -> SimpleMultiMicrogridEnv:\n",
    "    \"\"\"Create environment from config dict.\"\"\"\n",
    "    return SimpleMultiMicrogridEnv(\n",
    "        num_microgrids=config.get('num_microgrids', 3),\n",
    "        max_steps=config.get('max_steps', 96),\n",
    "        share_reward=config.get('share_reward', True),\n",
    "        penalty=config.get('penalty', 10.0),\n",
    "    )\n",
    "\n",
    "# Test\n",
    "env2 = create_env(env_config)\n",
    "print(f\"Created env with {env2.num_microgrids} microgrids, {env2.max_steps} max steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Key Takeaways\n\n1. **Environment Only Talks to L3 SystemAgent**\n   ```python\n   # All interaction through L3 - never directly touch L2/L1\n   self._grid_system.observe(...)\n   self._grid_system.act(...)\n   self._grid_system.update_from_environment(...)\n   ```\n\n2. **Complete Data Flow in `step()`**\n   ```python\n   def step(self, actions):\n       # 1. Observations: L1 → L2 → L3 → Env\n       sys_obs = self._grid_system.observe(global_state={})\n       \n       # 2. Actions: Env → L3 → L2 → L1\n       self._grid_system.act(sys_obs, upstream_action=actions)\n       \n       # 3. Physics (environment's job)\n       # ... run simulation ...\n       \n       # 4. State updates: Env → L3 → L2 → L1\n       self._grid_system.update_from_environment(env_state)\n       \n       # 5. Return observations: L1 → L2 → L3 → Env\n       return observations, rewards, ...\n   ```\n\n3. **Environment Owns Physics State**\n   ```python\n   self._physics = {\n       'frequency': 60.0,\n       'microgrids': {'mg_0': {'battery': {...}, 'generator': {...}}}\n   }\n   ```\n\n4. **Agents Don't Have `step()`**\n   - `observe()` — collect observations from hierarchy\n   - `act()` — distribute actions down hierarchy\n   - `update_from_environment()` — receive state updates\n   - Physics — environment's responsibility\n\n---\n\n**Next:** [04_training_with_rllib.ipynb](04_training_with_rllib.ipynb) - Training with MAPPO"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}